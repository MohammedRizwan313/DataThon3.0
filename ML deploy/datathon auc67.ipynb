{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FFyp7tfbMTVD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RMtikUSfMgW8"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Datathon_TrainData_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "Sv_IpMCkM_nm",
    "outputId": "9ce088dd-f0c0-4038-ce5b-82e77309eed8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text_of_Speech</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Running President/PM</th>\n",
       "      <th>Speech Link</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia</td>\n",
       "      <td>24-01-2000</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Speech at a conference of the heads of republi...</td>\n",
       "      <td>Esteemed Mr Lebedev,\\n\\nLadies and Gentlemen:\\...</td>\n",
       "      <td>President</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>http://en.kremlin.ru/events/president/transcri...</td>\n",
       "      <td>UPSET</td>\n",
       "      <td>OTHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USA</td>\n",
       "      <td>09-09-2021 00:00</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Remarks by President Biden on Fighting the COV...</td>\n",
       "      <td>THE PRESIDENT:  Good evening, my fellow Americ...</td>\n",
       "      <td>President</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>https://www.whitehouse.gov/briefing-room/speec...</td>\n",
       "      <td>OPTIMISM</td>\n",
       "      <td>DEVELOPMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Russia</td>\n",
       "      <td>24-12-2004</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Excerpts from the Opening Speech at a Session ...</td>\n",
       "      <td>Good afternoon, dear colleagues,\\n\\nOur meetin...</td>\n",
       "      <td>President</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>http://en.kremlin.ru/events/president/transcri...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>DEVELOPMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA</td>\n",
       "      <td>14-08-2014</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>\\nStatement by the President</td>\n",
       "      <td>Good afternoon, everybody. This sound system i...</td>\n",
       "      <td>President</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>https://obamawhitehouse.archives.gov/the-press...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>INTERNATIONAL AFFAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>26-03-2021 00:00</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Statement by President Biden on the Attack on ...</td>\n",
       "      <td>More Americans voted in the 2020 elections tha...</td>\n",
       "      <td>President</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>https://www.whitehouse.gov/briefing-room/speec...</td>\n",
       "      <td>UPSET</td>\n",
       "      <td>OTHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>24-Jul-19</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>Boris Johnson's first speech as Prime Minister...</td>\n",
       "      <td>Good afternoon I have just been to see Her Maj...</td>\n",
       "      <td>Prime Minister</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>https://www.gov.uk/government/speeches/boris-j...</td>\n",
       "      <td>OPTIMISM</td>\n",
       "      <td>DEVELOPMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>USA</td>\n",
       "      <td>01-02-2021 00:00</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Statement by President Joe Biden On Black Hist...</td>\n",
       "      <td>This February, during Black History Month, I c...</td>\n",
       "      <td>President</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>https://www.whitehouse.gov/briefing-room/state...</td>\n",
       "      <td>OPTIMISM</td>\n",
       "      <td>OTHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>USA</td>\n",
       "      <td>30-09-2015</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>\\nRemarks by the President Meeting with State ...</td>\n",
       "      <td>Thank you so much.  Everybody have a seat.  We...</td>\n",
       "      <td>President</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>https://obamawhitehouse.archives.gov/the-press...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>NATIONALISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>China</td>\n",
       "      <td>23-06-2021 00:00</td>\n",
       "      <td>H.E. Wang Yi</td>\n",
       "      <td>Let Us Strengthen Confidence and Solidarity an...</td>\n",
       "      <td>Colleagues,\\nFriends,\\n\\nIn 2013, President Xi...</td>\n",
       "      <td>State Councilor and Foreign Minister of the Pe...</td>\n",
       "      <td>Xi Jinping</td>\n",
       "      <td>https://www.fmprc.gov.cn/mfa_eng/wjdt_665385/z...</td>\n",
       "      <td>JOY</td>\n",
       "      <td>DEVELOPMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>China</td>\n",
       "      <td>06-06-2016 00:00</td>\n",
       "      <td>H.E. Xi Jinping</td>\n",
       "      <td>Making Unremitting Efforts for a New Model of ...</td>\n",
       "      <td>Secretary of State John Kerry,\\nSecretary of t...</td>\n",
       "      <td>President</td>\n",
       "      <td>Xi Jinping</td>\n",
       "      <td>https://www.fmprc.gov.cn/mfa_eng/wjdt_665385/z...</td>\n",
       "      <td>OPTIMISM</td>\n",
       "      <td>INTERNATIONAL AFFAIRS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1617 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Country              Date          Speaker  \\\n",
       "0             Russia        24-01-2000   Vladimir Putin   \n",
       "1                USA  09-09-2021 00:00        Joe Biden   \n",
       "2             Russia        24-12-2004   Vladimir Putin   \n",
       "3                USA        14-08-2014     Barack Obama   \n",
       "4                USA  26-03-2021 00:00        Joe Biden   \n",
       "...              ...               ...              ...   \n",
       "1612  United Kingdom         24-Jul-19    Boris Johnson   \n",
       "1613             USA  01-02-2021 00:00        Joe Biden   \n",
       "1614             USA        30-09-2015     Barack Obama   \n",
       "1615           China  23-06-2021 00:00     H.E. Wang Yi   \n",
       "1616           China  06-06-2016 00:00  H.E. Xi Jinping   \n",
       "\n",
       "                                               Headline  \\\n",
       "0     Speech at a conference of the heads of republi...   \n",
       "1     Remarks by President Biden on Fighting the COV...   \n",
       "2     Excerpts from the Opening Speech at a Session ...   \n",
       "3                          \\nStatement by the President   \n",
       "4     Statement by President Biden on the Attack on ...   \n",
       "...                                                 ...   \n",
       "1612  Boris Johnson's first speech as Prime Minister...   \n",
       "1613  Statement by President Joe Biden On Black Hist...   \n",
       "1614  \\nRemarks by the President Meeting with State ...   \n",
       "1615  Let Us Strengthen Confidence and Solidarity an...   \n",
       "1616  Making Unremitting Efforts for a New Model of ...   \n",
       "\n",
       "                                         Text_of_Speech  \\\n",
       "0     Esteemed Mr Lebedev,\\n\\nLadies and Gentlemen:\\...   \n",
       "1     THE PRESIDENT:  Good evening, my fellow Americ...   \n",
       "2     Good afternoon, dear colleagues,\\n\\nOur meetin...   \n",
       "3     Good afternoon, everybody. This sound system i...   \n",
       "4     More Americans voted in the 2020 elections tha...   \n",
       "...                                                 ...   \n",
       "1612  Good afternoon I have just been to see Her Maj...   \n",
       "1613  This February, during Black History Month, I c...   \n",
       "1614  Thank you so much.  Everybody have a seat.  We...   \n",
       "1615  Colleagues,\\nFriends,\\n\\nIn 2013, President Xi...   \n",
       "1616  Secretary of State John Kerry,\\nSecretary of t...   \n",
       "\n",
       "                                            Designation Running President/PM  \\\n",
       "0                                             President       Vladimir Putin   \n",
       "1                                             President            Joe Biden   \n",
       "2                                             President       Vladimir Putin   \n",
       "3                                             President         Barack Obama   \n",
       "4                                             President            Joe Biden   \n",
       "...                                                 ...                  ...   \n",
       "1612                                     Prime Minister        Boris Johnson   \n",
       "1613                                          President            Joe Biden   \n",
       "1614                                          President         Barack Obama   \n",
       "1615  State Councilor and Foreign Minister of the Pe...           Xi Jinping   \n",
       "1616                                          President           Xi Jinping   \n",
       "\n",
       "                                            Speech Link   Emotion  \\\n",
       "0     http://en.kremlin.ru/events/president/transcri...     UPSET   \n",
       "1     https://www.whitehouse.gov/briefing-room/speec...  OPTIMISM   \n",
       "2     http://en.kremlin.ru/events/president/transcri...   NEUTRAL   \n",
       "3     https://obamawhitehouse.archives.gov/the-press...   NEUTRAL   \n",
       "4     https://www.whitehouse.gov/briefing-room/speec...     UPSET   \n",
       "...                                                 ...       ...   \n",
       "1612  https://www.gov.uk/government/speeches/boris-j...  OPTIMISM   \n",
       "1613  https://www.whitehouse.gov/briefing-room/state...  OPTIMISM   \n",
       "1614  https://obamawhitehouse.archives.gov/the-press...   NEUTRAL   \n",
       "1615  https://www.fmprc.gov.cn/mfa_eng/wjdt_665385/z...       JOY   \n",
       "1616  https://www.fmprc.gov.cn/mfa_eng/wjdt_665385/z...  OPTIMISM   \n",
       "\n",
       "                    Context  \n",
       "0                    OTHERS  \n",
       "1               DEVELOPMENT  \n",
       "2               DEVELOPMENT  \n",
       "3     INTERNATIONAL AFFAIRS  \n",
       "4                    OTHERS  \n",
       "...                     ...  \n",
       "1612            DEVELOPMENT  \n",
       "1613                 OTHERS  \n",
       "1614            NATIONALISM  \n",
       "1615            DEVELOPMENT  \n",
       "1616  INTERNATIONAL AFFAIRS  \n",
       "\n",
       "[1617 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGJrL-RcNswp",
    "outputId": "37f272a6-772f-441a-bf34-c0947d16636c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\devayani\n",
      "[nltk_data]     ponduru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OGB5OY_LQYOn"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--dIoOF2QhY8",
    "outputId": "0c129b02-988c-43cc-c88b-b4a4cd61179d"
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aoglpsgVQ3NC"
   },
   "outputs": [],
   "source": [
    "df['Headline'] = df['Headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s0n0RZXRRHfX"
   },
   "outputs": [],
   "source": [
    "df['Headline'] = df['Headline'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CEDWu7vIRKqm"
   },
   "outputs": [],
   "source": [
    "df['Headline'] = df['Headline'].apply(lambda tokens: [re.sub(r'[^a-zA-Z0-9]', '', token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glGAlpAxSe3Z",
    "outputId": "41057843-80f2-4221-cd22-fe00f5c42b12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\devayani\n",
      "[nltk_data]     ponduru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "if 'Headline' in df.columns:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def preprocess_text(text):\n",
    "        if isinstance(text, str):\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            tokens = [token for token in tokens if token not in stop_words]\n",
    "            return ' '.join(tokens)\n",
    "        else:\n",
    "            return text\n",
    "    df['Headline'] = df['Headline'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDe9iseaTYaG",
    "outputId": "bf0c7d20-4be2-497d-bacb-8695c5e0c957"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\devayani\n",
      "[nltk_data]     ponduru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "if 'Headline' in df.columns:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    def preprocess_text(text):\n",
    "        if isinstance(text, str):\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            tokens = [token for token in tokens if token not in stop_words]\n",
    "            stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "            return ' '.join(stemmed_tokens)\n",
    "        else:\n",
    "            return text\n",
    "    df['Headline'] = df['Headline'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cDWxCPWFTvlr"
   },
   "outputs": [],
   "source": [
    "df['Headline'] = df['Headline'].apply(lambda tokens: [token if not token.isdigit() else 'NUM' for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uo2f7nKBT9na"
   },
   "outputs": [],
   "source": [
    "df['Headline'] = df['Headline'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GVWuaWLoUC10"
   },
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_datathon_traindata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6BMutDU8UIZS"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['Emotion'] = le.fit_transform(df['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dco8UYO-UgCg",
    "outputId": "67ea3910-c8ba-420f-bc7f-2bb9cb98a4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37267080745341613\n",
      "Confusion Matrix:\n",
      "[[21 10  5  0]\n",
      " [13 26 10  0]\n",
      " [13 23 12  0]\n",
      " [10 13  4  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         JOY       0.37      0.58      0.45        36\n",
      "     NEUTRAL       0.36      0.53      0.43        49\n",
      "    OPTIMISM       0.39      0.25      0.30        48\n",
      "       UPSET       1.00      0.04      0.07        28\n",
      "\n",
      "    accuracy                           0.37       161\n",
      "   macro avg       0.53      0.35      0.31       161\n",
      "weighted avg       0.48      0.37      0.33       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "df = pd.read_csv('preprocessed_datathon_traindata.csv')\n",
    "X = df['Text_of_Speech']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.391304347826087\n",
      "Confusion Matrix:\n",
      "[[20 10  5  1]\n",
      " [11 22 12  4]\n",
      " [11 22 14  1]\n",
      " [ 9  9  3  7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         JOY       0.39      0.56      0.46        36\n",
      "     NEUTRAL       0.35      0.45      0.39        49\n",
      "    OPTIMISM       0.41      0.29      0.34        48\n",
      "       UPSET       0.54      0.25      0.34        28\n",
      "\n",
      "    accuracy                           0.39       161\n",
      "   macro avg       0.42      0.39      0.38       161\n",
      "weighted avg       0.41      0.39      0.38       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('preprocessed_datathon_traindata.csv')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = df['Text_of_Speech']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Use a more advanced vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=0.1)  # Adjust alpha based on hyperparameter tuning\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.1\n",
      "Accuracy: 0.46105919003115264\n",
      "Confusion Matrix:\n",
      "[[46 20 10  2]\n",
      " [18 52 21  4]\n",
      " [19 38 34  1]\n",
      " [14 19  7 16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         JOY       0.47      0.59      0.53        78\n",
      "     NEUTRAL       0.40      0.55      0.46        95\n",
      "    OPTIMISM       0.47      0.37      0.41        92\n",
      "       UPSET       0.70      0.29      0.41        56\n",
      "\n",
      "    accuracy                           0.46       321\n",
      "   macro avg       0.51      0.45      0.45       321\n",
      "weighted avg       0.49      0.46      0.45       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('preprocessed_datathon_traindata.csv')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = df['Text_of_Speech']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a more advanced vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Perform hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0]}  # Adjust the alpha values as needed\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Train a Multinomial Naive Bayes model with the best alpha\n",
    "model = MultinomialNB(alpha=best_alpha)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Model: RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=300,\n",
      "                       random_state=42)\n",
      "Accuracy: 0.4735202492211838\n",
      "Confusion Matrix:\n",
      "[[50 15 13  0]\n",
      " [19 53 23  0]\n",
      " [13 33 46  0]\n",
      " [18 24 11  3]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         JOY       0.50      0.64      0.56        78\n",
      "     NEUTRAL       0.42      0.56      0.48        95\n",
      "    OPTIMISM       0.49      0.50      0.50        92\n",
      "       UPSET       1.00      0.05      0.10        56\n",
      "\n",
      "    accuracy                           0.47       321\n",
      "   macro avg       0.60      0.44      0.41       321\n",
      "weighted avg       0.56      0.47      0.44       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('preprocessed_datathon_traindata.csv')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = df['Text_of_Speech']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a more advanced vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Random Forest Model: {best_rf_model}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42679127725856697\n",
      "Confusion Matrix:\n",
      "[[42 21 14  1]\n",
      " [21 52 19  3]\n",
      " [21 38 31  2]\n",
      " [17 18  9 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         JOY       0.42      0.54      0.47        78\n",
      "     NEUTRAL       0.40      0.55      0.46        95\n",
      "    OPTIMISM       0.42      0.34      0.38        92\n",
      "       UPSET       0.67      0.21      0.32        56\n",
      "\n",
      "    accuracy                           0.43       321\n",
      "   macro avg       0.48      0.41      0.41       321\n",
      "weighted avg       0.46      0.43      0.42       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "8\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = df['Text_of_Speech']\n",
    "y = df['Emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use a different vectorizer or change vectorization parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Perform feature selection (SelectKBest with chi-squared test)\n",
    "selector = SelectKBest(chi2, k=2000)  # Adjust the number of features (k) as needed\n",
    "X_train_tfidf = selector.fit_transform(X_train_tfidf, y_train)\n",
    "X_test_tfidf = selector.transform(X_test_tfidf)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "model = MultinomialNB(alpha=0.1)  # You can adjust alpha if needed\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[42 21 14  1]\n",
      " [21 52 19  3]\n",
      " [21 38 31  2]\n",
      " [17 18  9 12]]\n",
      "Accurecy:\n",
      " 0.6911764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test, y_pred) \n",
    "print('confusion matrix:\\n',cm)\n",
    "\n",
    "accurecy=(cm[0][0] + cm[1][1])/(cm[0][0]+ cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accurecy:\\n\",accurecy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
