{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"c7bedcd9-d1a2-4892-b2d1-4fe688711a3a","_cell_guid":"a973f765-ff85-4e24-a9ee-86a98419bdc6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:04.310871Z","iopub.execute_input":"2023-09-09T00:13:04.311235Z","iopub.status.idle":"2023-09-09T00:13:04.658247Z","shell.execute_reply.started":"2023-09-09T00:13:04.311201Z","shell.execute_reply":"2023-09-09T00:13:04.657285Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/final-dataset/Datathon_TrainData_org.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport re","metadata":{"_uuid":"3421aadf-a117-4d1e-9585-23dbea8501c2","_cell_guid":"7d36911a-2335-46cb-a707-27323e96fd65","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:05.681238Z","iopub.execute_input":"2023-09-09T00:13:05.681886Z","iopub.status.idle":"2023-09-09T00:13:17.869401Z","shell.execute_reply.started":"2023-09-09T00:13:05.681851Z","shell.execute_reply":"2023-09-09T00:13:17.868470Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load your dataset\ndata = pd.read_csv('/kaggle/input/final-dataset/Datathon_TrainData_org.csv')","metadata":{"_uuid":"9e31484b-578b-4dc6-99b3-3dbe5b00f755","_cell_guid":"a71e4c43-8f39-42a9-80d5-37646ffedff5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:25.332685Z","iopub.execute_input":"2023-09-09T00:13:25.333048Z","iopub.status.idle":"2023-09-09T00:13:25.631977Z","shell.execute_reply.started":"2023-09-09T00:13:25.333018Z","shell.execute_reply":"2023-09-09T00:13:25.630975Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    if isinstance(text, str):\n        # Remove HTML tags and URLs\n        text = re.sub(r'<.*?>', '', text)\n        text = re.sub(r'http\\S+', '', text)\n        # Remove non-alphanumeric characters and extra spaces\n        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n    return text","metadata":{"_uuid":"6ca69a1f-9f1a-4845-8bbb-716762673b18","_cell_guid":"942b3bad-3925-4aa3-8616-3d7b195323a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:26.707529Z","iopub.execute_input":"2023-09-09T00:13:26.708233Z","iopub.status.idle":"2023-09-09T00:13:26.714922Z","shell.execute_reply.started":"2023-09-09T00:13:26.708199Z","shell.execute_reply":"2023-09-09T00:13:26.713889Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Handle missing values\ndata.fillna('', inplace=True)","metadata":{"_uuid":"7d9a067e-42f2-44d0-8f0a-23766237861b","_cell_guid":"41d73be0-a847-41fd-b5a3-9a6cbb39c8d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:27.873005Z","iopub.execute_input":"2023-09-09T00:13:27.873344Z","iopub.status.idle":"2023-09-09T00:13:27.882230Z","shell.execute_reply.started":"2023-09-09T00:13:27.873316Z","shell.execute_reply":"2023-09-09T00:13:27.881027Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Convert the 'Emotion' column to strings\ndata['Emotion'] = data['Emotion'].astype(str)","metadata":{"_uuid":"f5e10132-59c8-4446-8a1c-4b637682c6c2","_cell_guid":"814758f1-1729-4521-b422-769126660ac5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:28.919672Z","iopub.execute_input":"2023-09-09T00:13:28.920020Z","iopub.status.idle":"2023-09-09T00:13:28.929682Z","shell.execute_reply.started":"2023-09-09T00:13:28.919992Z","shell.execute_reply":"2023-09-09T00:13:28.928602Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Encode categorical variables (Country, Speaker, Designation, Running President/PM)\ndata = pd.get_dummies(data, columns=['Country', 'Speaker', 'Designation', 'Running President/PM'], drop_first=True)","metadata":{"_uuid":"0057c3f1-2696-45bb-9579-eb2ed6cbe03f","_cell_guid":"38810dc2-daa0-4675-a016-afe9aec22d96","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:31.905902Z","iopub.execute_input":"2023-09-09T00:13:31.906270Z","iopub.status.idle":"2023-09-09T00:13:31.927908Z","shell.execute_reply.started":"2023-09-09T00:13:31.906239Z","shell.execute_reply":"2023-09-09T00:13:31.926947Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Prepare the data\nX = data['Text_of_Speech']\ny = data['Emotion']","metadata":{"_uuid":"81952e27-8756-472c-980e-79cb612b5a26","_cell_guid":"d8716f69-85b7-4620-8a3a-133a856ea341","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:33.121174Z","iopub.execute_input":"2023-09-09T00:13:33.121470Z","iopub.status.idle":"2023-09-09T00:13:33.126885Z","shell.execute_reply.started":"2023-09-09T00:13:33.121445Z","shell.execute_reply":"2023-09-09T00:13:33.125952Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"_uuid":"408b7608-90a4-428f-b901-381a8072bdec","_cell_guid":"a79a01de-457a-460d-b140-1d4901cfc507","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:13:34.202221Z","iopub.execute_input":"2023-09-09T00:13:34.202779Z","iopub.status.idle":"2023-09-09T00:13:34.210706Z","shell.execute_reply.started":"2023-09-09T00:13:34.202744Z","shell.execute_reply":"2023-09-09T00:13:34.209764Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:15:01.977191Z","iopub.execute_input":"2023-09-09T00:15:01.977549Z","iopub.status.idle":"2023-09-09T00:15:01.982735Z","shell.execute_reply.started":"2023-09-09T00:15:01.977519Z","shell.execute_reply":"2023-09-09T00:15:01.981374Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Create a label encoder\nlabel_encoder = LabelEncoder()","metadata":{"_uuid":"2e650586-7bf6-421e-a3b5-22b25dd09089","_cell_guid":"a184c93f-285d-41d5-be04-5d3bf6daef4a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:15:07.599842Z","iopub.execute_input":"2023-09-09T00:15:07.600206Z","iopub.status.idle":"2023-09-09T00:15:07.604642Z","shell.execute_reply.started":"2023-09-09T00:15:07.600176Z","shell.execute_reply":"2023-09-09T00:15:07.603612Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Fit the label encoder on the emotion labels and transform them to numerical values\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)","metadata":{"_uuid":"3bb791a6-6569-4320-875a-23abbc08ad17","_cell_guid":"7debbcb1-8544-4081-9f68-69b093706eeb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:15:16.540667Z","iopub.execute_input":"2023-09-09T00:15:16.541014Z","iopub.status.idle":"2023-09-09T00:15:16.547173Z","shell.execute_reply.started":"2023-09-09T00:15:16.540987Z","shell.execute_reply":"2023-09-09T00:15:16.546080Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"num_labels=len(label_encoder.classes_)\nnum_labels","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:17:00.870560Z","iopub.execute_input":"2023-09-09T00:17:00.870944Z","iopub.status.idle":"2023-09-09T00:17:00.878045Z","shell.execute_reply.started":"2023-09-09T00:17:00.870912Z","shell.execute_reply":"2023-09-09T00:17:00.877125Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"model_name = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))","metadata":{"_uuid":"8780b482-69ad-42da-a3bf-f4e1d9ed2d60","_cell_guid":"7b065391-15f0-4122-97a1-e548752b969b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:15:17.877162Z","iopub.execute_input":"2023-09-09T00:15:17.877507Z","iopub.status.idle":"2023-09-09T00:15:21.825824Z","shell.execute_reply.started":"2023-09-09T00:15:17.877479Z","shell.execute_reply":"2023-09-09T00:15:21.824896Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5962ae67425c4ee3b9311f5dab887c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6bddfc9781d48ae941e7a6da40f4065"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9040d1f79a462b8c770d7e2a3c69e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfdd965ebcf43d5bfa017ff87e197a0"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize and encode the training data\nX_train_encoded = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt', max_length=512)\nX_test_encoded = tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors='pt', max_length=512)","metadata":{"_uuid":"04ab9031-c44c-4526-9737-370c493c2935","_cell_guid":"8931a086-ee0e-4cf6-9a09-9c7dfcd65f77","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:17:05.800233Z","iopub.execute_input":"2023-09-09T00:17:05.800606Z","iopub.status.idle":"2023-09-09T00:18:26.844508Z","shell.execute_reply.started":"2023-09-09T00:17:05.800555Z","shell.execute_reply":"2023-09-09T00:18:26.843548Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Convert the encoded inputs to PyTorch tensors\nX_train_input_ids = X_train_encoded['input_ids']\nX_train_attention_mask = X_train_encoded['attention_mask']\nX_test_input_ids = X_test_encoded['input_ids']\nX_test_attention_mask = X_test_encoded['attention_mask']","metadata":{"_uuid":"4c7e8ed3-b4e6-4b13-8ac3-1a59ebe21163","_cell_guid":"4af377a1-562b-45f3-887e-3edee3883b68","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:18:40.629107Z","iopub.execute_input":"2023-09-09T00:18:40.629655Z","iopub.status.idle":"2023-09-09T00:18:40.636967Z","shell.execute_reply.started":"2023-09-09T00:18:40.629556Z","shell.execute_reply":"2023-09-09T00:18:40.635870Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Convert labels to PyTorch tensors\ny_train_tensor = torch.tensor(y_train_encoded)\ny_test_tensor = torch.tensor(y_test_encoded)","metadata":{"_uuid":"b99f5a08-f7cb-4aa6-b676-ec88e71ae582","_cell_guid":"2f791c0d-48a9-42ae-a436-809cb8f8fe06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:18:41.812597Z","iopub.execute_input":"2023-09-09T00:18:41.813822Z","iopub.status.idle":"2023-09-09T00:18:41.822963Z","shell.execute_reply.started":"2023-09-09T00:18:41.813781Z","shell.execute_reply":"2023-09-09T00:18:41.821817Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for training data\ntrain_data = TensorDataset(X_train_input_ids, X_train_attention_mask, y_train_tensor)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)","metadata":{"_uuid":"470647fc-5b0b-4c18-9345-e038d5c79a93","_cell_guid":"67cc190b-eacc-4f02-8adf-92e2f08543ae","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:18:44.557046Z","iopub.execute_input":"2023-09-09T00:18:44.557446Z","iopub.status.idle":"2023-09-09T00:18:44.562661Z","shell.execute_reply.started":"2023-09-09T00:18:44.557417Z","shell.execute_reply":"2023-09-09T00:18:44.561700Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create DataLoader for testing data\ntest_data = TensorDataset(X_test_input_ids, X_test_attention_mask, y_test_tensor)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=16)","metadata":{"_uuid":"07ae19e8-9509-4fd0-88b2-40bcaa18d873","_cell_guid":"4d8963ae-ccde-4cc9-9647-8d25e5a4b1ac","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:18:45.778272Z","iopub.execute_input":"2023-09-09T00:18:45.778631Z","iopub.status.idle":"2023-09-09T00:18:45.784235Z","shell.execute_reply.started":"2023-09-09T00:18:45.778602Z","shell.execute_reply":"2023-09-09T00:18:45.783146Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)","metadata":{"_uuid":"1e1ffc48-71f8-461c-b21e-a5bb05b6836f","_cell_guid":"3efc0132-06c1-45ba-88d8-efe0167f48b0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:18:50.524062Z","iopub.execute_input":"2023-09-09T00:18:50.524420Z","iopub.status.idle":"2023-09-09T00:18:50.535717Z","shell.execute_reply.started":"2023-09-09T00:18:50.524393Z","shell.execute_reply":"2023-09-09T00:18:50.534548Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"_uuid":"1e6cded8-9f33-417d-b9eb-2e31bed93540","_cell_guid":"6dcb85ed-1523-4fc4-a7e4-a6a5e925a4eb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:19:12.132448Z","iopub.execute_input":"2023-09-09T00:19:12.133358Z","iopub.status.idle":"2023-09-09T00:19:16.931518Z","shell.execute_reply.started":"2023-09-09T00:19:12.133324Z","shell.execute_reply":"2023-09-09T00:19:16.930503Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define the number of training epochs\nnum_epochs = 3  # You can change this number to the desired number of epochs\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_dataloader:\n        input_ids, attention_mask, labels = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        labels = labels.to(device)\n\n        model.zero_grad()\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n\n        loss = outputs.loss\n        total_loss += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n\n    # Print progress after each epoch\n    print(f\"Epoch {epoch + 1}/{num_epochs} - Average Loss: {total_loss / len(train_dataloader)}\")\n\nprint(\"Training complete.\")","metadata":{"_uuid":"3b30d109-e5c2-4981-a72f-cd92eaa7f757","_cell_guid":"f62b7a50-3b21-4c58-b38e-65a015a93d62","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:19:24.118997Z","iopub.execute_input":"2023-09-09T00:19:24.119351Z","iopub.status.idle":"2023-09-09T00:22:46.200144Z","shell.execute_reply.started":"2023-09-09T00:19:24.119321Z","shell.execute_reply":"2023-09-09T00:22:46.199089Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/3 - Average Loss: 1.3490500773912595\nEpoch 2/3 - Average Loss: 1.1372075029361395\nEpoch 3/3 - Average Loss: 1.0171110872869138\nTraining complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\ny_true = []\ny_pred = []","metadata":{"_uuid":"8275d92d-f359-4f68-9618-caadd9275c33","_cell_guid":"1b54ce0a-8010-4afb-9538-21955c83e894","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:22:49.418066Z","iopub.execute_input":"2023-09-09T00:22:49.418414Z","iopub.status.idle":"2023-09-09T00:22:49.425026Z","shell.execute_reply.started":"2023-09-09T00:22:49.418385Z","shell.execute_reply":"2023-09-09T00:22:49.424089Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for batch in test_dataloader:\n    input_ids, attention_mask, labels = batch\n    input_ids = input_ids.to(device)\n    attention_mask = attention_mask.to(device)\n    labels = labels.to(device)\n\n    with torch.no_grad():\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=None\n        )\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=1)\n\n    y_true.extend(labels.cpu().numpy())\n    y_pred.extend(predictions.cpu().numpy())","metadata":{"_uuid":"67638d07-77a5-4856-8ac7-71fc0a321691","_cell_guid":"7cddf223-de5e-4995-90d7-2005dbb2c43d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:22:53.710354Z","iopub.execute_input":"2023-09-09T00:22:53.711885Z","iopub.status.idle":"2023-09-09T00:22:59.271301Z","shell.execute_reply.started":"2023-09-09T00:22:53.711841Z","shell.execute_reply":"2023-09-09T00:22:59.270309Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Decode numerical labels back to original emotions\ny_true = label_encoder.inverse_transform(y_true)\ny_pred = label_encoder.inverse_transform(y_pred)","metadata":{"_uuid":"3eb2b730-ba0c-44c1-8df7-19d06c6862de","_cell_guid":"00bafae1-8f0c-4644-b5ae-336fe8872c7a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:22:59.273330Z","iopub.execute_input":"2023-09-09T00:22:59.273708Z","iopub.status.idle":"2023-09-09T00:22:59.278936Z","shell.execute_reply.started":"2023-09-09T00:22:59.273675Z","shell.execute_reply":"2023-09-09T00:22:59.277869Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_true, y_pred)\nclassification_rep = classification_report(y_true, y_pred)\nconfusion_mat = confusion_matrix(y_true, y_pred)","metadata":{"_uuid":"47052657-ebfc-4ee8-8500-cf548bd10ecd","_cell_guid":"7da7e0fa-923d-4f39-8b8b-b0ee6d63a0a2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:23:02.556907Z","iopub.execute_input":"2023-09-09T00:23:02.557267Z","iopub.status.idle":"2023-09-09T00:23:02.592543Z","shell.execute_reply.started":"2023-09-09T00:23:02.557238Z","shell.execute_reply":"2023-09-09T00:23:02.591429Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Accuracy: {accuracy}\")\nprint(classification_rep)\nprint(\"Confusion Matrix:\")\nprint(confusion_mat)","metadata":{"_uuid":"0ef33358-eda5-4894-815a-8a1cbaf52ddb","_cell_guid":"a18a6e95-d455-4ce0-bd73-42c585e6aefb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-09T00:23:04.921287Z","iopub.execute_input":"2023-09-09T00:23:04.921738Z","iopub.status.idle":"2023-09-09T00:23:04.928011Z","shell.execute_reply.started":"2023-09-09T00:23:04.921702Z","shell.execute_reply":"2023-09-09T00:23:04.926974Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Accuracy: 0.5339506172839507\n              precision    recall  f1-score   support\n\n                   0.00      0.00      0.00         5\n         JOY       0.61      0.64      0.63        87\n     NEUTRAL       0.52      0.54      0.53       106\n    OPTIMISM       0.51      0.38      0.44        76\n       UPSET       0.47      0.62      0.53        50\n\n    accuracy                           0.53       324\n   macro avg       0.42      0.44      0.43       324\nweighted avg       0.53      0.53      0.53       324\n\nConfusion Matrix:\n[[ 0  5  0  0  0]\n [ 0 56 14 11  6]\n [ 0 15 57 15 19]\n [ 0 11 26 29 10]\n [ 0  5 12  2 31]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:23:14.585508Z","iopub.execute_input":"2023-09-09T00:23:14.585907Z","iopub.status.idle":"2023-09-09T00:23:14.591015Z","shell.execute_reply.started":"2023-09-09T00:23:14.585877Z","shell.execute_reply":"2023-09-09T00:23:14.589875Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'bert_emotion_model.pth')\n\n# Save the label encoder\njoblib.dump(label_encoder, 'label_encoder.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:23:16.880238Z","iopub.execute_input":"2023-09-09T00:23:16.880800Z","iopub.status.idle":"2023-09-09T00:23:17.495749Z","shell.execute_reply.started":"2023-09-09T00:23:16.880764Z","shell.execute_reply":"2023-09-09T00:23:17.494648Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['label_encoder.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\nimport joblib\n\n# Load the saved label encoder\nlabel_encoder = joblib.load('/kaggle/working/label_encoder.pkl')\n\n# Create a new instance of the model architecture\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_encoder.classes_))\n\n# Load the trained model weights\nmodel.load_state_dict(torch.load('/kaggle/working/bert_emotion_model.pth'))\nmodel.eval()\n\n# Tokenizer setup\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# Function to make predictions\ndef predict_emotion(input_text):\n    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt', max_length=512)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    logits = outputs.logits\n    predicted_class = torch.argmax(logits, dim=1).item()\n    \n    # Convert the predicted class back to emotion label\n    predicted_emotion = label_encoder.inverse_transform([predicted_class])\n    \n    return predicted_emotion[0]\n\n# Example usage\nuser_input = \"This is a test speech\"\npredicted_emotion = predict_emotion(user_input)\nprint(f\"Predicted Emotion: {predicted_emotion}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:23:22.098206Z","iopub.execute_input":"2023-09-09T00:23:22.098552Z","iopub.status.idle":"2023-09-09T00:23:24.146337Z","shell.execute_reply.started":"2023-09-09T00:23:22.098524Z","shell.execute_reply":"2023-09-09T00:23:24.145070Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Predicted Emotion: JOY\n","output_type":"stream"}]},{"cell_type":"code","source":"testdf=pd.read_csv('/kaggle/input/sample/TestData_org.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:35:06.586880Z","iopub.execute_input":"2023-09-09T00:35:06.587904Z","iopub.status.idle":"2023-09-09T00:35:06.636393Z","shell.execute_reply.started":"2023-09-09T00:35:06.587863Z","shell.execute_reply":"2023-09-09T00:35:06.635356Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"testdf=testdf[['Text_of_Speech']]","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:35:42.199031Z","iopub.execute_input":"2023-09-09T00:35:42.199867Z","iopub.status.idle":"2023-09-09T00:35:42.205886Z","shell.execute_reply.started":"2023-09-09T00:35:42.199822Z","shell.execute_reply":"2023-09-09T00:35:42.204780Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"testdf","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:35:47.974421Z","iopub.execute_input":"2023-09-09T00:35:47.975136Z","iopub.status.idle":"2023-09-09T00:35:47.986203Z","shell.execute_reply.started":"2023-09-09T00:35:47.975103Z","shell.execute_reply":"2023-09-09T00:35:47.984899Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                                        Text_of_Speech\n0    Good evening, everybody.  Please have a seat. ...\n1    Colleagues, we are meeting out of schedule tod...\n2    Now, one other thing I want to point out -- so...\n3    Good afternoon, everyone.  I just had the oppo...\n4     Well, I’ve got my team here to talk about Ebo...\n..                                                 ...\n397  THE PRESIDENT:  Thank you.  Thank you very muc...\n398  Good afternoon, dear colleagues,\\n\\nToday we a...\n399  Colleagues, welcome to this traditional meetin...\n400   Hi everybody.  Right now, the United States S...\n401  THE PRESIDENT:  Jocelyn, thank you.  Please.  ...\n\n[402 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text_of_Speech</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Good evening, everybody.  Please have a seat. ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Colleagues, we are meeting out of schedule tod...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Now, one other thing I want to point out -- so...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good afternoon, everyone.  I just had the oppo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Well, I’ve got my team here to talk about Ebo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>THE PRESIDENT:  Thank you.  Thank you very muc...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>Good afternoon, dear colleagues,\\n\\nToday we a...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>Colleagues, welcome to this traditional meetin...</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <td>Hi everybody.  Right now, the United States S...</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>THE PRESIDENT:  Jocelyn, thank you.  Please.  ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>402 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_csv_path = '/kaggle/working/outputtttt.csv'\n\n# Convert the DataFrame to a CSV file\ntestdf.to_csv(output_csv_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:40:07.774428Z","iopub.execute_input":"2023-09-09T00:40:07.775114Z","iopub.status.idle":"2023-09-09T00:40:07.910423Z","shell.execute_reply.started":"2023-09-09T00:40:07.775081Z","shell.execute_reply":"2023-09-09T00:40:07.909518Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load your input CSV file\ninput_csv_path = '/kaggle/working/outputtttt.csv'  # Update with the path to your CSV file\noutput_csv_path = '/kaggle/working/sampleoutput.csv'  # Update with the desired path for the output CSV file\n\n# Read the input CSV file into a DataFrame\ninput_df = pd.read_csv(input_csv_path)\n\n# Create an empty list to store the predicted emotions\npredicted_emotions = []\n\n# Iterate through each row in the input DataFrame\nfor index, row in input_df.iterrows():\n    input_text = row['Text_of_Speech']  # Replace 'Text_of_Speech' with the actual name of the text column\n    predicted_emotion = predict_emotion(input_text)\n    predicted_emotions.append(predicted_emotion)\n\n# Add the predicted emotions to the input DataFrame\ninput_df['predicted_emotion'] = predicted_emotions\n\n# Save the updated DataFrame to the output CSV file\ninput_df.to_csv(output_csv_path, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T00:55:18.144953Z","iopub.execute_input":"2023-09-09T00:55:18.145562Z","iopub.status.idle":"2023-09-09T00:57:07.342219Z","shell.execute_reply.started":"2023-09-09T00:55:18.145506Z","shell.execute_reply":"2023-09-09T00:57:07.340293Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m input_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     15\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText_of_Speech\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace 'Text_of_Speech' with the actual name of the text column\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     predicted_emotion \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     predicted_emotions\u001b[38;5;241m.\u001b[39mappend(predicted_emotion)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Add the predicted emotions to the input DataFrame\u001b[39;00m\n","Cell \u001b[0;32mIn[34], line 23\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(input_text, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 23\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     26\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1562\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    605\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 612\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:286\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    278\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 286\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"out=pd.read_csv('/kaggle/working/outputtttt.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:03:58.898745Z","iopub.execute_input":"2023-09-09T01:03:58.899125Z","iopub.status.idle":"2023-09-09T01:03:58.940296Z","shell.execute_reply.started":"2023-09-09T01:03:58.899095Z","shell.execute_reply":"2023-09-09T01:03:58.939382Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"a=out[\"Text_of_Speech\"]","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:04:39.582216Z","iopub.execute_input":"2023-09-09T01:04:39.583606Z","iopub.status.idle":"2023-09-09T01:04:39.590675Z","shell.execute_reply.started":"2023-09-09T01:04:39.583505Z","shell.execute_reply":"2023-09-09T01:04:39.589762Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:04:43.670730Z","iopub.execute_input":"2023-09-09T01:04:43.671086Z","iopub.status.idle":"2023-09-09T01:04:43.679225Z","shell.execute_reply.started":"2023-09-09T01:04:43.671056Z","shell.execute_reply":"2023-09-09T01:04:43.678313Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"0      Good evening, everybody.  Please have a seat. ...\n1      Colleagues, we are meeting out of schedule tod...\n2      Now, one other thing I want to point out -- so...\n3      Good afternoon, everyone.  I just had the oppo...\n4       Well, I’ve got my team here to talk about Ebo...\n                             ...                        \n397    THE PRESIDENT:  Thank you.  Thank you very muc...\n398    Good afternoon, dear colleagues,\\n\\nToday we a...\n399    Colleagues, welcome to this traditional meetin...\n400     Hi everybody.  Right now, the United States S...\n401    THE PRESIDENT:  Jocelyn, thank you.  Please.  ...\nName: Text_of_Speech, Length: 402, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\nimport joblib\n\n# Load the saved label encoder\nlabel_encoder = joblib.load('/kaggle/working/label_encoder.pkl')\n\n# Create a new instance of the model architecture\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_encoder.classes_))\n\n# Load the trained model weights\nmodel.load_state_dict(torch.load('/kaggle/working/bert_emotion_model.pth'))\nmodel.eval()\n\n# Tokenizer setup\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# Function to make predictions\ndef predict_emotion(input_text):\n    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt', max_length=512)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    logits = outputs.logits\n    predicted_class = torch.argmax(logits, dim=1).item()\n    \n    # Convert the predicted class back to emotion label\n    predicted_emotion = label_encoder.inverse_transform([predicted_class])\n    \n    return predicted_emotion[0]\n\n# Example usage\nresult=[]\nfor i in a:\n    user_input = i\n    predicted_emotion = predict_emotion(user_input)\n    result.append(predicted_emotion)\n#print(f\"Predicted Emotion: {predicted_emotion}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:06:10.024282Z","iopub.execute_input":"2023-09-09T01:06:10.024675Z","iopub.status.idle":"2023-09-09T01:11:57.835549Z","shell.execute_reply.started":"2023-09-09T01:06:10.024645Z","shell.execute_reply":"2023-09-09T01:11:57.834460Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:12:39.948374Z","iopub.execute_input":"2023-09-09T01:12:39.949073Z","iopub.status.idle":"2023-09-09T01:12:39.962926Z","shell.execute_reply.started":"2023-09-09T01:12:39.949037Z","shell.execute_reply":"2023-09-09T01:12:39.961890Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"['JOY',\n 'UPSET',\n 'OPTIMISM',\n 'UPSET',\n 'UPSET',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'UPSET',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'OPTIMISM',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'UPSET',\n 'UPSET',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'OPTIMISM',\n 'UPSET',\n 'JOY',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'UPSET',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'UPSET',\n 'OPTIMISM',\n 'JOY',\n 'UPSET',\n 'JOY',\n 'OPTIMISM',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'UPSET',\n 'JOY',\n 'JOY',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'UPSET',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'UPSET',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'OPTIMISM',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'UPSET',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'UPSET',\n 'OPTIMISM',\n 'UPSET',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'UPSET',\n 'JOY',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'OPTIMISM',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'UPSET',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'JOY',\n 'JOY',\n 'UPSET',\n 'NEUTRAL',\n 'OPTIMISM',\n 'UPSET',\n 'OPTIMISM',\n 'UPSET',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'UPSET',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'UPSET',\n 'OPTIMISM',\n 'OPTIMISM',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'JOY',\n 'NEUTRAL',\n 'OPTIMISM',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'OPTIMISM',\n 'OPTIMISM',\n 'OPTIMISM',\n 'OPTIMISM',\n 'JOY',\n 'OPTIMISM',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'UPSET',\n 'UPSET',\n 'NEUTRAL',\n 'NEUTRAL',\n 'JOY',\n 'NEUTRAL',\n 'JOY',\n 'OPTIMISM',\n 'JOY']"},"metadata":{}}]},{"cell_type":"code","source":"output_csv_path = '/kaggle/working/Rizwan1.csv'","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:19:42.232712Z","iopub.execute_input":"2023-09-09T01:19:42.233079Z","iopub.status.idle":"2023-09-09T01:19:42.237928Z","shell.execute_reply.started":"2023-09-09T01:19:42.233050Z","shell.execute_reply":"2023-09-09T01:19:42.236620Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"import csv","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:19:43.208181Z","iopub.execute_input":"2023-09-09T01:19:43.208508Z","iopub.status.idle":"2023-09-09T01:19:43.212876Z","shell.execute_reply.started":"2023-09-09T01:19:43.208479Z","shell.execute_reply":"2023-09-09T01:19:43.211711Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"with open(output_csv_path,mode='w',newline='') as file:\n    writer=csv.writer(file)\n    writer.writerow(result)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:19:44.453432Z","iopub.execute_input":"2023-09-09T01:19:44.454379Z","iopub.status.idle":"2023-09-09T01:19:44.460338Z","shell.execute_reply.started":"2023-09-09T01:19:44.454342Z","shell.execute_reply":"2023-09-09T01:19:44.459319Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"result.to_csv(output_csv_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:15:05.310686Z","iopub.execute_input":"2023-09-09T01:15:05.311058Z","iopub.status.idle":"2023-09-09T01:15:05.356489Z","shell.execute_reply.started":"2023-09-09T01:15:05.311023Z","shell.execute_reply":"2023-09-09T01:15:05.355253Z"},"trusted":true},"execution_count":62,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(output_csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'to_csv'","output_type":"error"}]},{"cell_type":"code","source":"horr=pd.read_csv('Rizwan1.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:20:41.357131Z","iopub.execute_input":"2023-09-09T01:20:41.357524Z","iopub.status.idle":"2023-09-09T01:20:41.425516Z","shell.execute_reply.started":"2023-09-09T01:20:41.357492Z","shell.execute_reply":"2023-09-09T01:20:41.424421Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"\n\n# Use the stack() method to convert the row elements into a single column\ndf_stacked = horr.stack().reset_index(drop=True).to_frame(name='result')\n\n# Save the resulting DataFrame to a CSV file\ndf_stacked.to_csv('output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:23:48.472133Z","iopub.execute_input":"2023-09-09T01:23:48.472509Z","iopub.status.idle":"2023-09-09T01:23:48.482341Z","shell.execute_reply.started":"2023-09-09T01:23:48.472478Z","shell.execute_reply":"2023-09-09T01:23:48.481396Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"res=pd.read_csv('/kaggle/working/output.csv')\nres","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:25:24.533618Z","iopub.execute_input":"2023-09-09T01:25:24.534001Z","iopub.status.idle":"2023-09-09T01:25:24.545533Z","shell.execute_reply.started":"2023-09-09T01:25:24.533971Z","shell.execute_reply":"2023-09-09T01:25:24.544484Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [result]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"with open(\"output.csv\", newline = \"\",mode = \"w\") as file:\n    writer = csv.writer(file)\n    writer.writerows([item] for item in result)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T01:32:50.982456Z","iopub.execute_input":"2023-09-09T01:32:50.983441Z","iopub.status.idle":"2023-09-09T01:32:50.990025Z","shell.execute_reply.started":"2023-09-09T01:32:50.983408Z","shell.execute_reply":"2023-09-09T01:32:50.989050Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}